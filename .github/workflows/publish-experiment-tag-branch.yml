name: Publish Experiment Tag Branch to S3

on:
  workflow_dispatch:
    inputs:
      branch:
        description: 'Branch to deploy from'
        required: true
        default: 'main'

jobs:
  authorize:
    name: Authorize
    runs-on: ubuntu-latest
    steps:
      - name: ${{ github.actor }} permission check
        uses: 'lannonbr/repo-permission-check-action@2.0.2'
        with:
          permission: 'write'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  build-and-deploy:
    runs-on: ubuntu-latest
    needs: [authorize]
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Setup Node
        uses: actions/setup-node@v3
        with:
          node-version: '16'
          cache: 'yarn'

      - name: Set up SSH for deploy key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.DOM_MUTATOR_ACCESS_KEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan github.com >> ~/.ssh/known_hosts

      - name: Install dependencies
        run: yarn install --frozen-lockfile

      - name: Build experiment-tag
        run: cd packages/experiment-tag && yarn build

      - name: Get branch name
        id: branch-name
        run: |
          BRANCH_NAME="${{ github.event.inputs.branch }}"
          # Replace slashes with dashes for S3 key compatibility
          BRANCH_NAME_SAFE=$(echo $BRANCH_NAME | sed 's/\//-/g')
          echo "branch_name_safe=$BRANCH_NAME_SAFE" >> $GITHUB_OUTPUT

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-west-2

      - name: Upload to S3 with branch name
        env:
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          BRANCH_NAME: ${{ steps.branch-name.outputs.branch_name_safe }}
        run: |
          # Create a temporary script for branch-specific upload
          cat > scripts/upload-experiment-tag-branch.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const {
            S3Client,
            PutObjectCommand,
            HeadObjectCommand,
          } = require('@aws-sdk/client-s3');

          const bucket = process.env.S3_BUCKET_NAME;
          const packageJson = require('../packages/experiment-tag/package.json');
          const name = 'experiment-tag';
          const version = packageJson.version;
          const branchName = process.env.BRANCH_NAME;
          const location = path.join(process.cwd(), 'packages/experiment-tag/dist');
          
          // Only include the gzipped file
          const files = [
            {
              file: 'experiment-tag.umd.js.gz',
              gzipped: true,
            },
          ];

          let deployedCount = 0;

          console.log('[Publish to AWS S3] START');
          const promises = files.map(({ file, gzipped }) => {
            const body = fs.readFileSync(path.join(location, file));
            // Create the key with version and branch name but remove .gz extension
            const key = `libs/${file
              .replace('experiment-tag', `${name}-${version}-${branchName}`)
              .replace('.gz', '')}`;
            const client = new S3Client();

            const headObject = new HeadObjectCommand({
              Bucket: bucket,
              Key: key,
            });
            console.log(
              `[Publish to AWS S3] Checking if ${key} exists in target bucket...`,
            );
            return client
              .send(headObject)
              .then(() => {
                console.log(
                  `[Publish to AWS S3] ${key} exists in target bucket. Overwriting...`,
                );
                // Always upload even if exists to ensure latest branch version
                const putObject = new PutObjectCommand({
                  ACL: 'public-read',
                  Body: body,
                  Bucket: bucket,
                  CacheControl: 'max-age=31536000',
                  ContentType: 'application/javascript',
                  ContentEncoding: 'gzip',
                  Key: key,
                });
                return client
                  .send(putObject)
                  .then(() => {
                    console.log(`[Publish to AWS S3] Upload success for ${key}.`);
                    deployedCount += 1;
                  })
                  .catch(console.error);
              })
              .catch(() => {
                console.log(
                  `[Publish to AWS S3] ${key} does not exist in target bucket. Uploading to S3...`,
                );
                const putObject = new PutObjectCommand({
                  ACL: 'public-read',
                  Body: body,
                  Bucket: bucket,
                  CacheControl: 'max-age=31536000',
                  ContentType: 'application/javascript',
                  ContentEncoding: 'gzip',
                  Key: key,
                });
                return client
                  .send(putObject)
                  .then(() => {
                    console.log(`[Publish to AWS S3] Upload success for ${key}.`);
                    deployedCount += 1;
                  })
                  .catch(console.error);
              });
          });

          Promise.all(promises)
            .then(() => {
              if (deployedCount === 0) {
                console.log(`[Publish to AWS S3] Complete! Nothing to deploy.`);
              } else {
                console.log(
                  `[Publish to AWS S3] Success! Deployed ${deployedCount}/${files.length} files.`,
                );
              }
              console.log('[Publish to AWS S3] END');
            })
            .catch(console.log);
          EOF

          # Run the branch-specific upload script
          node scripts/upload-experiment-tag-branch.js
